"""
Multi-Image Analysis Node - å¤šå›¾åƒåˆ†æèŠ‚ç‚¹
æ”¯æŒè¾“å…¥å¤šå¼ å›¾åƒè¿›è¡Œå¯¹æ¯”åˆ†æ
"""

import os
import sys
import torch
from pathlib import Path
from PIL import Image
from torchvision.transforms import ToPILImage
import folder_paths

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
module_path = Path(__file__).parent.parent
if str(module_path) not in sys.path:
    sys.path.insert(0, str(module_path))

try:
    from core.inference.transformers_engine import TransformersInferenceEngine
    from utils.system_prompts import SystemPromptsManager
    from config.node_definitions import (
        SEED_INPUT,
        TEMPERATURE_INPUT,
        PROMPT_INPUT,
        SYSTEM_PROMPT_INPUT,
        TEXT_OUTPUT,
        merge_inputs
    )
except ImportError:
    from ..core.inference.transformers_engine import TransformersInferenceEngine
    from ..utils.system_prompts import SystemPromptsManager
    from ..config.node_definitions import (
        SEED_INPUT,
        TEMPERATURE_INPUT,
        PROMPT_INPUT,
        SYSTEM_PROMPT_INPUT,
        TEXT_OUTPUT,
        merge_inputs
    )


class MultiImageAnalysis:
    """å¤šå›¾åƒåˆ†æèŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": merge_inputs(
                {
                    "model_config": ("TRANSFORMERS_MODEL",),
                },
                PROMPT_INPUT,
                TEMPERATURE_INPUT,
                {
                    "max_tokens": (
                        "INT",
                        {
                            "default": 2048,
                            "min": 128,
                            "max": 256000,
                            "step": 1,
                            "tooltip": "ğŸ¤– æœ€å¤§ç”Ÿæˆ token æ•°"
                        }
                    ),
                },
                SEED_INPUT
            ),
            "optional": {
                "image_1": ("IMAGE",),
                "image_2": ("IMAGE",),
                "image_3": ("IMAGE",),
                "image_4": ("IMAGE",),
                "image_5": ("IMAGE",),
                "image_6": ("IMAGE",),
                "system_prompt": (
                    "STRING",
                    {
                        "default": "",
                        "multiline": True,
                        "tooltip": "ğŸ¤– ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰"
                    }
                ),
            }
        }
    
    RETURN_TYPES = TEXT_OUTPUT["types"]
    RETURN_NAMES = TEXT_OUTPUT["names"]
    FUNCTION = "analyze_images"
    CATEGORY = "ğŸ¤– GGUF-LLM/Multi-Image"
    OUTPUT_NODE = True
    
    def analyze_images(
        self,
        model_config,
        prompt,
        temperature,
        max_tokens,
        seed,
        image_1=None,
        image_2=None,
        image_3=None,
        image_4=None,
        image_5=None,
        image_6=None,
        system_prompt=""
    ):
        """åˆ†æå¤šå¼ å›¾åƒ"""
        
        # è·å–å¼•æ“
        from .vision_node_transformers import VisionModelLoaderTransformers
        engine = VisionModelLoaderTransformers._get_engine()
        
        # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
        if engine.model is None or engine.processor is None:
            print("âš ï¸  Model not loaded, loading now...")
            success = engine.load_model(model_config)
            if not success:
                raise RuntimeError(f"Failed to load model: {model_config.get('model_name', 'unknown')}")
        
        # æ”¶é›†æ‰€æœ‰è¾“å…¥çš„å›¾åƒ
        images = []
        temp_paths = []
        
        for idx, image in enumerate([image_1, image_2, image_3, image_4, image_5, image_6], 1):
            if image is not None:
                pil_image = ToPILImage()(image[0].permute(2, 0, 1))
                temp_path = Path(folder_paths.temp_directory) / f"multi_image_{seed}_{idx}.png"
                pil_image.save(temp_path)
                temp_paths.append(temp_path)
                images.append(temp_path)
        
        if not images:
            raise ValueError("è‡³å°‘éœ€è¦æä¾›ä¸€å¼ å›¾åƒ")
        
        print(f"ğŸ“¸ Analyzing {len(images)} images")
        
        # æ„å»ºæ¶ˆæ¯ï¼ˆQwen3-VL æ ¼å¼ï¼‰
        messages = []
        
        # æ„å»ºç”¨æˆ·æ¶ˆæ¯å†…å®¹ï¼ˆåŒ…å«æ‰€æœ‰å›¾åƒå’Œæ–‡æœ¬ï¼‰
        user_content = []
        
        # æ·»åŠ æ‰€æœ‰å›¾åƒ
        for temp_path in temp_paths:
            user_content.append({
                "type": "ğŸ¤– image",
                "image": str(temp_path)
            })
        
        # æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼ˆå¦‚æœæœ‰ï¼‰ä½œä¸ºæ–‡æœ¬å‰ç¼€
        if system_prompt and system_prompt.strip():
            user_content.append({
                "type": "ğŸ¤– text",
                "text": f"{system_prompt.strip()}\n\n{prompt}"
            })
        else:
            # ä½¿ç”¨å¤šå›¾åƒåˆ†æçš„é»˜è®¤ç³»ç»Ÿæç¤ºè¯
            default_prompt = (
                "You are an expert image analyst. When given multiple images, "
                "carefully compare and analyze them, identifying similarities, "
                "differences, patterns, and relationships between the images."
            )
            user_content.append({
                "type": "ğŸ¤– text",
                "text": f"{default_prompt}\n\n{prompt}"
            })
        
        messages.append({
            "role": "ğŸ¤– user",
            "content": user_content
        })
        
        # æ‰§è¡Œæ¨ç†
        try:
            result = engine.inference(
                messages=messages,
                temperature=temperature,
                max_new_tokens=max_tokens,
                top_p=0.8,
                top_k=20,
                repetition_penalty=1.0,
                seed=seed
            )
            
            print(f"âœ… Analysis complete ({len(result)} chars)")
            print(f"   Images analyzed: {len(images)}")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for temp_path in temp_paths:
                if temp_path.exists():
                    temp_path.unlink()
            
            # å¦‚æœä¸ä¿æŒåŠ è½½ï¼Œå¸è½½æ¨¡å‹
            if not model_config.get("keep_loaded", False):
                engine.unload()
            
            return (result,)
            
        except Exception as e:
            print(f"âŒ Analysis failed: {e}")
            import traceback
            traceback.print_exc()
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for temp_path in temp_paths:
                if temp_path.exists():
                    temp_path.unlink()
            
            raise


class MultiImageComparison:
    """å¤šå›¾åƒå¯¹æ¯”èŠ‚ç‚¹ï¼ˆé¢„è®¾æç¤ºè¯ï¼‰"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model_config": ("TRANSFORMERS_MODEL",),
                "comparison_type": (
                    [
                        "similarities - æ‰¾å‡ºç›¸ä¼¼ä¹‹å¤„",
                        "differences - æ‰¾å‡ºä¸åŒä¹‹å¤„",
                        "changes - åˆ†æå˜åŒ–",
                        "relationships - åˆ†æå…³ç³»",
                        "sequence - åˆ†æé¡ºåº",
                        "quality - è´¨é‡å¯¹æ¯”",
                        "style - é£æ ¼å¯¹æ¯”",
                        "custom - è‡ªå®šä¹‰",
                    ],
                    {
                        "default": "ğŸ¤– similarities - æ‰¾å‡ºç›¸ä¼¼ä¹‹å¤„",
                        "tooltip": "ğŸ¤– å¯¹æ¯”ç±»å‹"
                    }
                ),
                "custom_prompt": (
                    "STRING",
                    {
                        "default": "",
                        "multiline": True,
                        "tooltip": "ğŸ¤– è‡ªå®šä¹‰æç¤ºè¯ï¼ˆå½“é€‰æ‹© custom æ—¶ä½¿ç”¨ï¼‰"
                    }
                ),
                **TEMPERATURE_INPUT,
                **{
                    "max_tokens": (
                        "INT",
                        {
                            "default": 2048,
                            "min": 128,
                            "max": 256000,
                            "step": 1,
                            "tooltip": "ğŸ¤– æœ€å¤§ç”Ÿæˆ token æ•°"
                        }
                    ),
                },
                **SEED_INPUT,
            },
            "optional": {
                "image_1": ("IMAGE",),
                "image_2": ("IMAGE",),
                "image_3": ("IMAGE",),
                "image_4": ("IMAGE",),
                "image_5": ("IMAGE",),
                "image_6": ("IMAGE",),
            }
        }
    
    RETURN_TYPES = TEXT_OUTPUT["types"]
    RETURN_NAMES = TEXT_OUTPUT["names"]
    FUNCTION = "compare_images"
    CATEGORY = "ğŸ¤– GGUF-LLM/Multi-Image"
    OUTPUT_NODE = True
    
    # é¢„è®¾æç¤ºè¯
    COMPARISON_PROMPTS = {
        "similarities": "ğŸ¤– Identify and describe the similarities between these images. Focus on common elements, themes, colors, compositions, and subjects.",
        "differences": "ğŸ¤– Identify and describe the differences between these images. Focus on what makes each image unique.",
        "changes": "ğŸ¤– Analyze the changes across these images. Describe what has changed from one image to the next.",
        "relationships": "ğŸ¤– Analyze the relationships between these images. How do they relate to each other? What story do they tell together?",
        "sequence": "ğŸ¤– Analyze these images as a sequence. Describe the progression or timeline they represent.",
        "quality": "ğŸ¤– Compare the quality of these images. Analyze aspects like resolution, clarity, composition, lighting, and technical execution.",
        "style": "ğŸ¤– Compare the artistic style of these images. Analyze the visual style, artistic techniques, and aesthetic choices.",
    }
    
    def compare_images(
        self,
        model_config,
        comparison_type,
        custom_prompt,
        temperature,
        max_tokens,
        seed,
        image_1=None,
        image_2=None,
        image_3=None,
        image_4=None,
        image_5=None,
        image_6=None
    ):
        """å¯¹æ¯”å¤šå¼ å›¾åƒ"""
        
        # è§£æå¯¹æ¯”ç±»å‹
        comp_key = comparison_type.split(" - ")[0]
        
        # ç¡®å®šæç¤ºè¯
        if comp_key == "custom":
            if not custom_prompt or not custom_prompt.strip():
                raise ValueError("è¯·æä¾›è‡ªå®šä¹‰æç¤ºè¯")
            prompt = custom_prompt.strip()
        else:
            prompt = self.COMPARISON_PROMPTS.get(comp_key, self.COMPARISON_PROMPTS["similarities"])
        
        print(f"ğŸ” Comparison type: {comparison_type}")
        
        # ä½¿ç”¨ MultiImageAnalysis çš„é€»è¾‘
        analyzer = MultiImageAnalysis()
        return analyzer.analyze_images(
            model_config=model_config,
            prompt=prompt,
            temperature=temperature,
            max_tokens=max_tokens,
            seed=seed,
            image_1=image_1,
            image_2=image_2,
            image_3=image_3,
            image_4=image_4,
            image_5=image_5,
            image_6=image_6,
            system_prompt=""
        )


# å¯¼å‡ºèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "MultiImageAnalysis": MultiImageAnalysis,
    "MultiImageComparison": MultiImageComparison,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "MultiImageAnalysis": "ğŸ¤– Multi-Image Analysis",
    "MultiImageComparison": "ğŸ¤– Multi-Image Comparison",
}
