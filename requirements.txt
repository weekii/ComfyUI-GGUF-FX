llama-cpp-python>=0.2.0
Pillow>=9.0.0
numpy>=1.20.0
requests>=2.25.0
transformers>=4.51.0
accelerate>=0.20.0