llama-cpp-python>=0.2.0
Pillow>=9.0.0
numpy>=1.20.0
requests>=2.25.0
