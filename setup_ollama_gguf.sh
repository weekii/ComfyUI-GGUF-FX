#!/bin/bash

################################################################################
# Ollama + GGUF æ¨¡å‹å¿«é€Ÿå®‰è£…è„šæœ¬
# 
# åŠŸèƒ½:
# - å®‰è£… Ollama åˆ° /workspace/ollama
# - ä»ç°æœ‰ GGUF æ–‡ä»¶åˆ›å»º Ollama æ¨¡å‹
# - é…ç½®å¹¶å¯åŠ¨ Ollama æœåŠ¡
# - æµ‹è¯•æ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
#
# ä½¿ç”¨æ–¹æ³•:
#   chmod +x setup_ollama_gguf.sh
#   ./setup_ollama_gguf.sh
################################################################################

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ‰“å°å‡½æ•°
print_header() {
    echo -e "${BLUE}================================${NC}"
    echo -e "${BLUE}$1${NC}"
    echo -e "${BLUE}================================${NC}"
}

print_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

print_error() {
    echo -e "${RED}âŒ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}"
}

print_info() {
    echo -e "${BLUE}â„¹ï¸  $1${NC}"
}

# é…ç½®å˜é‡
OLLAMA_DIR="/workspace/ollama"
OLLAMA_MODELS_DIR="$OLLAMA_DIR/models"
OLLAMA_PORT="11434"
COMFYUI_MODELS_DIR="/workspace/ComfyUI/models/LLM/GGUF"

################################################################################
# 1. æ£€æŸ¥ç¯å¢ƒ
################################################################################
print_header "æ£€æŸ¥ç¯å¢ƒ"

# æ£€æŸ¥æ˜¯å¦æœ‰ root æƒé™
if [ "$EUID" -ne 0 ]; then 
    print_warning "å»ºè®®ä½¿ç”¨ root æƒé™è¿è¡Œæ­¤è„šæœ¬"
fi

# æ£€æŸ¥ GGUF æ¨¡å‹ç›®å½•
if [ ! -d "$COMFYUI_MODELS_DIR" ]; then
    print_error "GGUF æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: $COMFYUI_MODELS_DIR"
    exit 1
fi

# åˆ—å‡ºå¯ç”¨çš„ GGUF æ¨¡å‹
print_info "å¯ç”¨çš„ GGUF æ¨¡å‹:"
GGUF_FILES=($(find "$COMFYUI_MODELS_DIR" -name "*.gguf" -type f))
if [ ${#GGUF_FILES[@]} -eq 0 ]; then
    print_error "æœªæ‰¾åˆ°ä»»ä½• GGUF æ¨¡å‹æ–‡ä»¶"
    exit 1
fi

for i in "${!GGUF_FILES[@]}"; do
    filename=$(basename "${GGUF_FILES[$i]}")
    size=$(du -h "${GGUF_FILES[$i]}" | cut -f1)
    echo "  [$i] $filename ($size)"
done

print_success "ç¯å¢ƒæ£€æŸ¥å®Œæˆ"

################################################################################
# 2. å®‰è£… Ollama
################################################################################
print_header "å®‰è£… Ollama"

# æ£€æŸ¥æ˜¯å¦å·²å®‰è£…
if command -v ollama &> /dev/null; then
    OLLAMA_VERSION=$(ollama --version 2>&1 | head -1)
    print_info "Ollama å·²å®‰è£…: $OLLAMA_VERSION"
    read -p "æ˜¯å¦é‡æ–°å®‰è£…? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        print_info "è·³è¿‡ Ollama å®‰è£…"
    else
        print_info "é‡æ–°å®‰è£… Ollama..."
        curl -fsSL https://ollama.com/install.sh | sh
    fi
else
    print_info "å¼€å§‹å®‰è£… Ollama..."
    curl -fsSL https://ollama.com/install.sh | sh
fi

# éªŒè¯å®‰è£…
if command -v ollama &> /dev/null; then
    print_success "Ollama å®‰è£…æˆåŠŸ"
    ollama --version
else
    print_error "Ollama å®‰è£…å¤±è´¥"
    exit 1
fi

################################################################################
# 3. é…ç½® Ollama ç›®å½•
################################################################################
print_header "é…ç½® Ollama ç›®å½•"

# åˆ›å»ºç›®å½•
mkdir -p "$OLLAMA_DIR"
mkdir -p "$OLLAMA_MODELS_DIR"

print_success "Ollama ç›®å½•åˆ›å»ºå®Œæˆ: $OLLAMA_DIR"

################################################################################
# 4. åœæ­¢ç°æœ‰ Ollama æœåŠ¡
################################################################################
print_header "åœæ­¢ç°æœ‰æœåŠ¡"

if pgrep -x "ollama" > /dev/null; then
    print_info "åœæ­¢ç°æœ‰ Ollama æœåŠ¡..."
    pkill -9 ollama || true
    sleep 2
fi

print_success "ç°æœ‰æœåŠ¡å·²åœæ­¢"

################################################################################
# 5. å¯åŠ¨ Ollama æœåŠ¡
################################################################################
print_header "å¯åŠ¨ Ollama æœåŠ¡"

# è®¾ç½®ç¯å¢ƒå˜é‡
export OLLAMA_HOST="127.0.0.1:$OLLAMA_PORT"
export OLLAMA_MODELS="$OLLAMA_MODELS_DIR"

print_info "é…ç½®:"
print_info "  ç«¯å£: $OLLAMA_PORT"
print_info "  æ¨¡å‹ç›®å½•: $OLLAMA_MODELS_DIR"

# å¯åŠ¨æœåŠ¡ï¼ˆåå°è¿è¡Œï¼‰
nohup ollama serve > /tmp/ollama.log 2>&1 &
OLLAMA_PID=$!

print_info "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 5

# æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
if ps -p $OLLAMA_PID > /dev/null; then
    print_success "Ollama æœåŠ¡å·²å¯åŠ¨ (PID: $OLLAMA_PID)"
else
    print_error "Ollama æœåŠ¡å¯åŠ¨å¤±è´¥"
    cat /tmp/ollama.log
    exit 1
fi

# æµ‹è¯•è¿æ¥
print_info "æµ‹è¯•æœåŠ¡è¿æ¥..."
for i in {1..10}; do
    if curl -s http://127.0.0.1:$OLLAMA_PORT/api/tags > /dev/null 2>&1; then
        print_success "æœåŠ¡è¿æ¥æˆåŠŸ"
        break
    fi
    if [ $i -eq 10 ]; then
        print_error "æ— æ³•è¿æ¥åˆ° Ollama æœåŠ¡"
        exit 1
    fi
    sleep 1
done

################################################################################
# 6. åˆ›å»º GGUF æ¨¡å‹
################################################################################
print_header "åˆ›å»º GGUF æ¨¡å‹"

echo ""
print_info "è¯·é€‰æ‹©è¦å¯¼å…¥çš„ GGUF æ¨¡å‹:"
for i in "${!GGUF_FILES[@]}"; do
    filename=$(basename "${GGUF_FILES[$i]}")
    size=$(du -h "${GGUF_FILES[$i]}" | cut -f1)
    echo "  [$i] $filename ($size)"
done

read -p "è¯·è¾“å…¥æ¨¡å‹ç¼–å· (0-$((${#GGUF_FILES[@]}-1))): " MODEL_INDEX

if [ -z "$MODEL_INDEX" ] || [ "$MODEL_INDEX" -lt 0 ] || [ "$MODEL_INDEX" -ge ${#GGUF_FILES[@]} ]; then
    print_error "æ— æ•ˆçš„æ¨¡å‹ç¼–å·"
    exit 1
fi

SELECTED_GGUF="${GGUF_FILES[$MODEL_INDEX]}"
GGUF_FILENAME=$(basename "$SELECTED_GGUF")
GGUF_BASENAME="${GGUF_FILENAME%.gguf}"

print_info "é€‰æ‹©çš„æ¨¡å‹: $GGUF_FILENAME"

# ç”Ÿæˆæ¨¡å‹åç§°ï¼ˆå°å†™ï¼Œæ›¿æ¢ç‰¹æ®Šå­—ç¬¦ï¼‰
MODEL_NAME=$(echo "$GGUF_BASENAME" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9._-]/-/g')
print_info "Ollama æ¨¡å‹åç§°: $MODEL_NAME"

# åˆ›å»º Modelfile
MODELFILE_PATH="/tmp/Modelfile_$MODEL_NAME"
cat > "$MODELFILE_PATH" << EOF
FROM $SELECTED_GGUF

# æ¨¡å‹å‚æ•°
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER repeat_penalty 1.1

# ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
SYSTEM """
You are a helpful AI assistant.
"""
EOF

print_success "Modelfile å·²åˆ›å»º: $MODELFILE_PATH"

# åˆ›å»ºæ¨¡å‹
print_info "å¼€å§‹åˆ›å»º Ollama æ¨¡å‹..."
print_info "è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…..."

if ollama create "$MODEL_NAME" -f "$MODELFILE_PATH"; then
    print_success "æ¨¡å‹åˆ›å»ºæˆåŠŸ: $MODEL_NAME"
else
    print_error "æ¨¡å‹åˆ›å»ºå¤±è´¥"
    exit 1
fi

################################################################################
# 7. éªŒè¯æ¨¡å‹
################################################################################
print_header "éªŒè¯æ¨¡å‹"

print_info "åˆ—å‡ºæ‰€æœ‰æ¨¡å‹:"
ollama list

print_info "æµ‹è¯•æ¨¡å‹ç”Ÿæˆ..."
TEST_RESPONSE=$(ollama run "$MODEL_NAME" "Say hello in one sentence" 2>&1 | head -5)
echo "$TEST_RESPONSE"

if [ -n "$TEST_RESPONSE" ]; then
    print_success "æ¨¡å‹æµ‹è¯•æˆåŠŸ"
else
    print_warning "æ¨¡å‹æµ‹è¯•å¯èƒ½å¤±è´¥ï¼Œè¯·æ£€æŸ¥"
fi

################################################################################
# 8. åˆ›å»ºç®¡ç†è„šæœ¬
################################################################################
print_header "åˆ›å»ºç®¡ç†è„šæœ¬"

# å¯åŠ¨è„šæœ¬
cat > "$OLLAMA_DIR/start.sh" << 'EOF'
#!/bin/bash
export OLLAMA_HOST="127.0.0.1:11434"
export OLLAMA_MODELS="/workspace/ollama/models"
nohup ollama serve > /tmp/ollama.log 2>&1 &
echo "Ollama æœåŠ¡å·²å¯åŠ¨"
echo "PID: $(pgrep ollama)"
echo "æ—¥å¿—: /tmp/ollama.log"
EOF

# åœæ­¢è„šæœ¬
cat > "$OLLAMA_DIR/stop.sh" << 'EOF'
#!/bin/bash
pkill ollama
echo "Ollama æœåŠ¡å·²åœæ­¢"
EOF

# çŠ¶æ€è„šæœ¬
cat > "$OLLAMA_DIR/status.sh" << 'EOF'
#!/bin/bash
if pgrep -x "ollama" > /dev/null; then
    echo "âœ… Ollama æœåŠ¡è¿è¡Œä¸­"
    echo "PID: $(pgrep ollama)"
    echo "ç«¯å£: 11434"
    echo ""
    echo "æ¨¡å‹åˆ—è¡¨:"
    ollama list
else
    echo "âŒ Ollama æœåŠ¡æœªè¿è¡Œ"
fi
EOF

# æµ‹è¯•è„šæœ¬
cat > "$OLLAMA_DIR/test.sh" << EOF
#!/bin/bash
echo "æµ‹è¯• Ollama æœåŠ¡..."
curl -s http://127.0.0.1:11434/api/tags | python3 -m json.tool

echo ""
echo "æµ‹è¯•æ¨¡å‹: $MODEL_NAME"
ollama run "$MODEL_NAME" "Hello, how are you?"
EOF

chmod +x "$OLLAMA_DIR"/*.sh

print_success "ç®¡ç†è„šæœ¬å·²åˆ›å»º:"
print_info "  å¯åŠ¨: $OLLAMA_DIR/start.sh"
print_info "  åœæ­¢: $OLLAMA_DIR/stop.sh"
print_info "  çŠ¶æ€: $OLLAMA_DIR/status.sh"
print_info "  æµ‹è¯•: $OLLAMA_DIR/test.sh"

################################################################################
# 9. åˆ›å»º systemd æœåŠ¡ï¼ˆå¯é€‰ï¼‰
################################################################################
print_header "åˆ›å»ºç³»ç»ŸæœåŠ¡ï¼ˆå¯é€‰ï¼‰"

read -p "æ˜¯å¦åˆ›å»º systemd æœåŠ¡ä»¥å¼€æœºè‡ªå¯? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    cat > /etc/systemd/system/ollama.service << EOF
[Unit]
Description=Ollama Service
After=network.target

[Service]
Type=simple
User=root
Environment="OLLAMA_HOST=127.0.0.1:11434"
Environment="OLLAMA_MODELS=/workspace/ollama/models"
ExecStart=/usr/local/bin/ollama serve
Restart=always
RestartSec=3

[Install]
WantedBy=multi-user.target
EOF

    systemctl daemon-reload
    systemctl enable ollama
    print_success "systemd æœåŠ¡å·²åˆ›å»ºå¹¶å¯ç”¨"
    print_info "ä½¿ç”¨ 'systemctl start/stop/status ollama' ç®¡ç†æœåŠ¡"
else
    print_info "è·³è¿‡ systemd æœåŠ¡åˆ›å»º"
fi

################################################################################
# 10. æ€»ç»“
################################################################################
print_header "å®‰è£…å®Œæˆ"

echo ""
print_success "ğŸ‰ Ollama + GGUF å®‰è£…å®Œæˆï¼"
echo ""

print_info "ğŸ“Š å®‰è£…ä¿¡æ¯:"
echo "  Ollama ç›®å½•: $OLLAMA_DIR"
echo "  æ¨¡å‹ç›®å½•: $OLLAMA_MODELS_DIR"
echo "  æœåŠ¡ç«¯å£: $OLLAMA_PORT"
echo "  æœåŠ¡åœ°å€: http://127.0.0.1:$OLLAMA_PORT"
echo "  æ¨¡å‹åç§°: $MODEL_NAME"
echo "  æ—¥å¿—æ–‡ä»¶: /tmp/ollama.log"

echo ""
print_info "ğŸš€ å¿«é€Ÿå¼€å§‹:"
echo "  1. æµ‹è¯•æœåŠ¡: curl http://127.0.0.1:$OLLAMA_PORT/api/tags"
echo "  2. è¿è¡Œæ¨¡å‹: ollama run $MODEL_NAME"
echo "  3. æŸ¥çœ‹çŠ¶æ€: $OLLAMA_DIR/status.sh"

echo ""
print_info "ğŸ”§ åœ¨ ComfyUI ä¸­ä½¿ç”¨:"
echo "  1. æ·»åŠ  'Unified Text Model Selector' èŠ‚ç‚¹"
echo "  2. è®¾ç½®å‚æ•°:"
echo "     - mode: Remote (API)"
echo "     - base_url: http://127.0.0.1:$OLLAMA_PORT"
echo "     - api_type: Ollama"
echo "     - remote_model: $MODEL_NAME"
echo "  3. è¿æ¥ 'Unified Text Generation' èŠ‚ç‚¹"
echo "  4. è¿è¡Œç”Ÿæˆ"

echo ""
print_info "ğŸ“š ç®¡ç†å‘½ä»¤:"
echo "  å¯åŠ¨æœåŠ¡: $OLLAMA_DIR/start.sh"
echo "  åœæ­¢æœåŠ¡: $OLLAMA_DIR/stop.sh"
echo "  æŸ¥çœ‹çŠ¶æ€: $OLLAMA_DIR/status.sh"
echo "  æµ‹è¯•æ¨¡å‹: $OLLAMA_DIR/test.sh"

echo ""
print_info "ğŸ“ æ·»åŠ æ›´å¤šæ¨¡å‹:"
echo "  1. å°† GGUF æ–‡ä»¶æ”¾åˆ°: $COMFYUI_MODELS_DIR"
echo "  2. é‡æ–°è¿è¡Œæ­¤è„šæœ¬"
echo "  æˆ–æ‰‹åŠ¨åˆ›å»º:"
echo "     ollama create <model-name> -f <Modelfile>"

echo ""
print_success "âœ¨ å®‰è£…å®Œæˆï¼äº«å—ä½¿ç”¨ Ollamaï¼"
